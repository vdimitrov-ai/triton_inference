version: '3.8'
services:
  triton_hf_transformer_example:
    command: ["--model-repository=/models", "--log-info=1"]
    build: .
    shm_size: '16gb'
    restart: unless-stopped
    ports:
      - 8500:8000
      - 8501:8001
      - 8502:8002
    volumes:
      - ./:/workspace
      - ./model_repository:/models
      - ./assets:/assets
    environment:
      - LC_ALL=C.UTF-8
      - LANG=C.UTF-8
    deploy:
      resources:
        limits:
            cpus: '8'
        reservations:
          devices:
          - driver: nvidia
            device_ids: ['0']
            capabilities: [gpu]
